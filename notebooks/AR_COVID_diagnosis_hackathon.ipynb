{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy_of_COVID_diagnosis_hackathon.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bbc/apprenticeship-covid-hack/blob/main/notebooks/AR_COVID_diagnosis_hackathon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFzda9am9vnj"
      },
      "source": [
        "# Covid-19 diagnosis using symptoms\n",
        "\n",
        "[Prateek Gupta](https://www.pgupta.info) \n",
        "\n",
        "2020-05-20\n",
        "\n",
        "**Abstract:** This notebook is a tutorial on building a typical machine learning classifier. \n",
        "The process of doing so spans steps ranging from data wrangling to model selection. \n",
        "With the help of each of these steps we hope to make the reader familiar with challenges involved in building a machine learning system. \n",
        "\n",
        "# Question\n",
        "\n",
        "In this hackathon, we want to build a machine learning model to predict COVID-19 infections from symptoms.\n",
        "It has several applications, for example, triaging patients to be attended to by a doctor or nurse, recommending self-isolation through contact tracing apps. \n",
        "\n",
        "Zoabi et al. [[1]](https://www.nature.com/articles/s41746-020-00372-6) builds a decision tree classifier using the publicly available data reported by the Israeli Ministry of Health.\n",
        "The paper itself dicsusses the various challenges encountered in deploying such a model. \n",
        "It is encouraged to read the paper and learn the challeges and ways to overcome them. \n",
        "\n",
        "However, in this hackathon, we will use their dataset and make the participant familiar with a typical pipeline of building a machine learning system.\n",
        "\n",
        "[1] [Zoabi, Y., Deri-Rozov, S. & Shomron, N. Machine learning-based prediction of COVID-19 diagnosis based on symptoms. npj Digit. Med. 4, 3 (2021).]((https://www.nature.com/articles/s41746-020-00372-6))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfQWCQDjAKN0"
      },
      "source": [
        "# Setup the workspace\n",
        "\n",
        "We will clone their Git repository to to use their dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yguOIEDX-YbD",
        "outputId": "4ee1a4fe-c628-4786-ca6f-46945e098f10"
      },
      "source": [
        "!git clone https://github.com/nshomron/covidpred.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'covidpred' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35jfRmroICGw"
      },
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import plot_roc_curve, roc_auc_score, roc_curve\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kv6FR_gOAV16"
      },
      "source": [
        "# Data \n",
        "\n",
        "Let's check how the data looks like and how various features are encoded. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7tANpd5-tqj",
        "outputId": "467652a6-5098-45f2-986e-53ec6168985a"
      },
      "source": [
        "df = pd.read_csv('covidpred/data/corona_tested_individuals_ver_006.english.csv.zip')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (1,2,3,4,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXaLQdbBAElY",
        "outputId": "509f46a5-6718-4f10-a4f6-606649205ebc"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['test_date', 'cough', 'fever', 'sore_throat', 'shortness_of_breath',\n",
              "       'head_ache', 'corona_result', 'age_60_and_above', 'gender',\n",
              "       'test_indication'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcqoo0VIFKNP",
        "outputId": "1684b4b4-9fb2-419b-fdea-2ce25e3b9f1b"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 278848 entries, 0 to 278847\n",
            "Data columns (total 10 columns):\n",
            " #   Column               Non-Null Count   Dtype \n",
            "---  ------               --------------   ----- \n",
            " 0   test_date            278848 non-null  object\n",
            " 1   cough                278848 non-null  object\n",
            " 2   fever                278848 non-null  object\n",
            " 3   sore_throat          278848 non-null  object\n",
            " 4   shortness_of_breath  278848 non-null  object\n",
            " 5   head_ache            278848 non-null  object\n",
            " 6   corona_result        278848 non-null  object\n",
            " 7   age_60_and_above     278848 non-null  object\n",
            " 8   gender               278848 non-null  object\n",
            " 9   test_indication      278848 non-null  object\n",
            "dtypes: object(10)\n",
            "memory usage: 21.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "is7St--3FV7t",
        "outputId": "cba63366-bc0b-4710-9920-fb13ad6c4d9f"
      },
      "source": [
        "for column in df.columns:\n",
        "  print(df[column].value_counts())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2020-04-20    10921\n",
            "2020-04-19    10199\n",
            "2020-04-22     9646\n",
            "2020-04-21     9624\n",
            "2020-04-16     9138\n",
            "2020-04-23     8744\n",
            "2020-04-01     8654\n",
            "2020-04-13     8425\n",
            "2020-04-02     8188\n",
            "2020-04-03     8079\n",
            "2020-04-17     7645\n",
            "2020-04-05     7509\n",
            "2020-04-30     7313\n",
            "2020-04-27     7304\n",
            "2020-04-15     7149\n",
            "2020-03-31     7134\n",
            "2020-04-24     7028\n",
            "2020-03-26     6663\n",
            "2020-04-14     6571\n",
            "2020-04-28     6334\n",
            "2020-04-18     6321\n",
            "2020-04-26     6131\n",
            "2020-04-12     5984\n",
            "2020-03-27     5963\n",
            "2020-04-07     5931\n",
            "2020-03-30     5915\n",
            "2020-04-10     5678\n",
            "2020-03-28     5602\n",
            "2020-03-25     5495\n",
            "2020-04-06     5368\n",
            "2020-03-29     5277\n",
            "2020-04-04     5145\n",
            "2020-04-25     5052\n",
            "2020-03-24     4735\n",
            "2020-04-09     4539\n",
            "2020-04-11     4341\n",
            "2020-04-29     4259\n",
            "2020-04-08     4058\n",
            "2020-03-22     3565\n",
            "2020-03-23     3494\n",
            "2020-03-19     2243\n",
            "2020-03-18     1991\n",
            "2020-03-20     1870\n",
            "2020-03-21     1648\n",
            "2020-03-17     1463\n",
            "2020-03-16     1304\n",
            "2020-03-15      985\n",
            "2020-03-13      686\n",
            "2020-03-12      634\n",
            "2020-03-14      609\n",
            "2020-03-11      294\n",
            "Name: test_date, dtype: int64\n",
            "0       121649\n",
            "0       114719\n",
            "1        25875\n",
            "1        16353\n",
            "None       252\n",
            "Name: cough, dtype: int64\n",
            "0       133942\n",
            "0       122902\n",
            "1        13582\n",
            "1         8170\n",
            "None       252\n",
            "Name: fever, dtype: int64\n",
            "0       260664\n",
            "0        16257\n",
            "1         1480\n",
            "1          446\n",
            "None         1\n",
            "Name: sore_throat, dtype: int64\n",
            "0       261079\n",
            "0        16191\n",
            "1         1065\n",
            "1          512\n",
            "None         1\n",
            "Name: shortness_of_breath, dtype: int64\n",
            "0       260079\n",
            "0        16354\n",
            "1         2065\n",
            "1          349\n",
            "None         1\n",
            "Name: head_ache, dtype: int64\n",
            "negative    260227\n",
            "positive     14729\n",
            "other         3892\n",
            "Name: corona_result, dtype: int64\n",
            "None    127320\n",
            "No      125703\n",
            "Yes      25825\n",
            "Name: age_60_and_above, dtype: int64\n",
            "female    130158\n",
            "male      129127\n",
            "None       19563\n",
            "Name: gender, dtype: int64\n",
            "Other                     242741\n",
            "Abroad                     25468\n",
            "Contact with confirmed     10639\n",
            "Name: test_indication, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWHY4TLAAhpJ"
      },
      "source": [
        "Great! These are the features used in the paper for their prediction task. The authors also list these features in the [README.md of their Github repo](https://github.com/nshomron/covidpred). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEtPMd2qGn72"
      },
      "source": [
        "Pandas read columns as string, so we need to convert them to the proper format before we can operate on it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi7esn5RGdC8"
      },
      "source": [
        "df['test_date'] = pd.to_datetime(df['test_date'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mdb3D7Y5BdTt",
        "outputId": "46f9a757-0863-4524-ec84-a607228450e4"
      },
      "source": [
        "print(\"Start date:\", min(df['test_date']))\n",
        "print(\"End date:\", max(df['test_date']))\n",
        "\n",
        "n_days = (max(df['test_date']) - min(df['test_date'])).days\n",
        "print(\"# of days: \", n_days)\n",
        "\n",
        "n_obs =  df.shape[0]\n",
        "print(\"# of observations:\", df.shape[0])\n",
        "print(\"# of features:\", df.shape[1])\n",
        "\n",
        "pos_cases = sum(df['corona_result'] == \"positive\")\n",
        "print(\"# of positively diagnosed cases: {0} ({1: 2.2f}%)\".format(pos_cases, 100*pos_cases / n_obs))\n",
        "\n",
        "neg_cases = sum(df['corona_result'] == \"negative\")\n",
        "print(\"# of negatively diagnosed cases: {0} ({1: 2.2f}%)\".format(neg_cases, 100 * neg_cases / n_obs))\n",
        "\n",
        "other_cases = sum(df['corona_result'] == \"other\") # possibly not confirmed\n",
        "print(\"# of other cases (possibly, not confirmed): {0} ({1: 2.2f}%)\".format(other_cases, 100 * other_cases / n_obs))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start date: 2020-03-11 00:00:00\n",
            "End date: 2020-04-30 00:00:00\n",
            "# of days:  50\n",
            "# of observations: 278848\n",
            "# of features: 10\n",
            "# of positively diagnosed cases: 14729 ( 5.28%)\n",
            "# of negatively diagnosed cases: 260227 ( 93.32%)\n",
            "# of other cases (possibly, not confirmed): 3892 ( 1.40%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7guFsw8K-Cvy"
      },
      "source": [
        "Since we do not have any information on what happened to \"other\" cases, we will exclude them from our exercise. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-2eeGvK-Bxv"
      },
      "source": [
        "df = df[df['corona_result'].isin(['positive', 'negative'])]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hG2lfabKr1e"
      },
      "source": [
        "To build out predictor, we will be splitting our dataset into **training,  validation, and test sets**. \n",
        "A model is trained on the training dataset while the hyperparameters are tuned on the validation dataset. \n",
        "Finally, a test dataset is used to report final model's performance metrics. \n",
        "\n",
        "Since we have a time dependent dataset we will split our training and test dataset based on time. \n",
        "Thus, we find the date before which 60% of observations are present, and use that as our training dataset.\n",
        "We will use next 20% of the dataset as our validation dataset, and finally, the remaining 20% will be used as a test dataset. \n",
        "Thus, we use 60-20-20 split.\n",
        "\n",
        "The authors use 63%-23% training-test split, and a further split of training into train-valid dataset using 80-20% split.\n",
        "There is no prescribed formula on how to do this split. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0dEh77THGW6"
      },
      "source": [
        "date_counts = df.groupby(['test_date']).count()['gender'] # take count of any column. They will all be same.\n",
        "date_counts = date_counts.sort_index()\n",
        "cum_counts = date_counts.cumsum()\n",
        "cdf = cum_counts / n_obs\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvTrB-PsMrOv",
        "outputId": "59828845-b576-4ddb-f9f4-5086a320331b"
      },
      "source": [
        "max_training_date = cdf[cdf < 0.60].index.max()\n",
        "training_data = df[df['test_date'] <= max_training_date]\n",
        "\n",
        "min_test_date = cdf[cdf > 0.80].index.min()\n",
        "test_data = df[df['test_date'] >= min_test_date]\n",
        "\n",
        "valid_data = df[(max_training_date < df['test_date']) & (df['test_date'] < min_test_date)]\n",
        "\n",
        "print(\"# of observations in training dataset\", training_data.shape[0])\n",
        "print(\"# of observations in validation dataset\", valid_data.shape[0])\n",
        "print(\"# of observations in test dataset\", test_data.shape[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of observations in training dataset 160717\n",
            "# of observations in validation dataset 53172\n",
            "# of observations in test dataset 61067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSlfzz6DTVMx"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def normalise(x):\n",
        "  if type(x) == str:\n",
        "    return int(x) if x != \"None\" else 2\n",
        "  return x\n",
        "\n",
        "symptoms = [\"cough\",\"fever\",\"sore_throat\",\"shortness_of_breath\",\"head_ache\"]\n",
        "categorical = [\"age_60_and_above\",\"gender\",\"test_indication\"]\n",
        "\n",
        "#Clean inconsitent datatypes within symptom columns\n",
        "for col in symptoms:\n",
        "  df.loc[:, col] = df[col].apply(normalise)\n",
        "\n",
        "X = df.drop(\"test_date\",axis=1)\n",
        "y = X[\"corona_result\"]\n",
        "\n",
        "#Split off training data and then spliut the remaining into validation and test\n",
        "training_data, X_rem, y_train, y_rem = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)\n",
        "valid_data, test_data, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5, random_state=42, stratify=y_rem)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-xJrSsa5_Lz"
      },
      "source": [
        "**NOTE:**\n",
        "It is **extremely important** that you do not use the test dataset in the model building phase. \n",
        "While building models, it is required to tune the hyperparameter, adjust assumptions, modify features, etc. \n",
        "This should be done on the validation dataset. \n",
        "After several such iterations on the validation dataset, you will pick a model with the best performace as your final model. \n",
        "\n",
        "A test dataset is used to measure the final model's performance, which is a proxy for how it will perform (or generalize) in real life. \n",
        "Thus, to have a proper measure of model's genearalization, test dataset should not be part of your model building process. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W86CzZGp_rOd"
      },
      "source": [
        "# Exploratory Data Analysis\n",
        "\n",
        "In this section, we will see the general statistics of features.\n",
        "In doing so, we will encounter inconsistencies in the data and address them accordingly. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jx1mMFLQEMdS",
        "outputId": "2b194d51-9ee4-4769-9133-ef1920f12f08"
      },
      "source": [
        "# We want to predict 'corona_result'. \n",
        "# We will not use \"test_date\" as a feature. \n",
        "# So we narrow down the input features to this list \n",
        "INPUT_FEATURES = ['cough', 'fever', 'sore_throat', 'shortness_of_breath', 'head_ache', 'age_60_and_above', 'gender', 'test_indication']\n",
        "TARGET_COLUMN = 'corona_result'\n",
        "\n",
        "for col in INPUT_FEATURES:\n",
        "  print(\"*\"*25, f\" {col} \", \"*\"*25)\n",
        "  print(training_data[col].value_counts())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************************  cough  *************************\n",
            "0    156362\n",
            "1     27701\n",
            "2       157\n",
            "Name: cough, dtype: int64\n",
            "*************************  fever  *************************\n",
            "0    169732\n",
            "1     14330\n",
            "2       158\n",
            "Name: fever, dtype: int64\n",
            "*************************  sore_throat  *************************\n",
            "0    182950\n",
            "1      1269\n",
            "2         1\n",
            "Name: sore_throat, dtype: int64\n",
            "*************************  shortness_of_breath  *************************\n",
            "0    183164\n",
            "1      1055\n",
            "2         1\n",
            "Name: shortness_of_breath, dtype: int64\n",
            "*************************  head_ache  *************************\n",
            "0    182641\n",
            "1      1578\n",
            "2         1\n",
            "Name: head_ache, dtype: int64\n",
            "*************************  age_60_and_above  *************************\n",
            "None    83971\n",
            "No      83273\n",
            "Yes     16976\n",
            "Name: age_60_and_above, dtype: int64\n",
            "*************************  gender  *************************\n",
            "female    86083\n",
            "male      85281\n",
            "None      12856\n",
            "Name: gender, dtype: int64\n",
            "*************************  test_indication  *************************\n",
            "Other                     160398\n",
            "Abroad                     16759\n",
            "Contact with confirmed      7063\n",
            "Name: test_indication, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9srJ86HQZ6xF"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-bVRyzjR-dU"
      },
      "source": [
        "Here are the questions to guide you through the process of exploring data \n",
        "\n",
        "1.   Think about possible biases and limitations of this dataset\n",
        "2.   What is the format of feature values? Are there any inconsistencies? If so, how would you make them cosistent?\n",
        "3.   What is the statistics of these feature values? How many symptoms are reported or not?\n",
        "4.   Which symptoms have a reporting bias, i.e., likely to be reported when the patient is COVID positive? \n",
        "5.   How will the symptoms with reporting bias affect the model’s performance?\n",
        "6.   Visualization: Draw the bar graph of features grouped by the target class? \n",
        "7.   How does the bar graph of the symptoms with reporting bias looks like?\n",
        "8.   Determine if we have a class imbalance in the dataset? If so, what do you reckon will be the downstream challenges in evaluating the model? How will you overcome those challenges?\n",
        "\n",
        "All of the following are discrete classes: ['cough', 'fever', 'sore_throat', 'shortness_of_breath', 'head_ache', 'age_60_and_above', 'gender', 'test_indication']\n",
        "\n",
        "'cough': Imbalanced in favour of “0”\n",
        "\n",
        "'fever': Imbalanced in favour of “0”\n",
        "\n",
        "'sore_throat': Imbalanced in favour of “0”\n",
        "\n",
        "'shortness_of_breath': Imbalanced in favour of “0”\n",
        "\n",
        "'head_ache': Imbalanced in favour of “0”\n",
        "\n",
        "'age_60_and_above': Imbalanced in favour of “No”\n",
        "\n",
        "'gender': Balanced\n",
        "\n",
        "'test_indication': Imbalanced in favour of “Other”\n",
        "\n",
        "\n",
        "9.   What does \"None\" value mean for feature? Should we include these features?\n",
        "\n",
        "At first view there is no “non-null” value detected by Pandas.\n",
        "\n",
        "'cough’: 252 - result most probably negative (86% of the time). Correlation with cough when value is 'None'. Only 9% are negative and over 60.\n",
        "\n",
        "'fever': 252 - result most probably negative (86% of the time). Correlation with cough when value is 'None'.\n",
        "\n",
        "'sore_throat': 1\n",
        "\n",
        "'shortness_of_breath': 1\n",
        "\n",
        "'head_ache': 1\n",
        "\n",
        "'age_60_and_above': 125664 - result most probably negative (97% of the time)\n",
        "\n",
        "'gender': 19045 -  result most probably negative (94% of the time)\n",
        "\n",
        "'test_indication': No none values - But other is 97% negative\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OR5gHbNbIG7",
        "outputId": "64bbe9dc-969a-4869-e48a-d4e70fcbceca"
      },
      "source": [
        "df_gender_none = df[df['gender']=='None']\n",
        "print(len(df_gender_none))\n",
        "print(len(df_gender_none[df_gender_none['corona_result'] == 'negative']))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19045\n",
            "17876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMgSPtofeeE8",
        "outputId": "bd10167f-5906-459a-e729-6c0b26ff1e8b"
      },
      "source": [
        "df_60_none = df[df['age_60_and_above']=='None']\n",
        "print(len(df_60_none))\n",
        "print(len(df_60_none[df_60_none['corona_result'] == 'negative']))\n",
        "df_60_negative = df[df['corona_result'] == 'negative']\n",
        "print(df_60_negative.shape)\n",
        "df_60_negative[df_60_negative['age_60_and_above']=='Yes'].shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125664\n",
            "122404\n",
            "(260227, 10)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23221, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "ZjnWEYi7fNoG",
        "outputId": "88c173ae-8921-463e-dabc-d3b811279753"
      },
      "source": [
        "df_fever_none = df[df['fever']=='None']\n",
        "df_fever_none\n",
        "print(len(df_fever_none))\n",
        "print(len(df_fever_none[df_fever_none['cough'] == 'None']))\n",
        "print(len(df_fever_none[df_fever_none['corona_result'] == 'negative']))\n",
        "df_fever_none[df_fever_none['cough'] != 'None']"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_date</th>\n",
              "      <th>cough</th>\n",
              "      <th>fever</th>\n",
              "      <th>sore_throat</th>\n",
              "      <th>shortness_of_breath</th>\n",
              "      <th>head_ache</th>\n",
              "      <th>corona_result</th>\n",
              "      <th>age_60_and_above</th>\n",
              "      <th>gender</th>\n",
              "      <th>test_indication</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [test_date, cough, fever, sore_throat, shortness_of_breath, head_ache, corona_result, age_60_and_above, gender, test_indication]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "VbsOdHvWh8yI",
        "outputId": "ae043d4b-d318-44fb-fb9e-dbf803f5f23f"
      },
      "source": [
        "df_cough_none = df[df['cough']=='None']\n",
        "df_cough_none\n",
        "print(len(df_cough_none))\n",
        "print(len(df_cough_none[df_cough_none['fever'] == 'None']))\n",
        "print(len(df_cough_none[df_cough_none['corona_result'] == 'negative']))\n",
        "df_cough_none[df_cough_none['fever'] != 'None']"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_date</th>\n",
              "      <th>cough</th>\n",
              "      <th>fever</th>\n",
              "      <th>sore_throat</th>\n",
              "      <th>shortness_of_breath</th>\n",
              "      <th>head_ache</th>\n",
              "      <th>corona_result</th>\n",
              "      <th>age_60_and_above</th>\n",
              "      <th>gender</th>\n",
              "      <th>test_indication</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [test_date, cough, fever, sore_throat, shortness_of_breath, head_ache, corona_result, age_60_and_above, gender, test_indication]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yApLNdLmoO8s",
        "outputId": "af97858f-1f07-48d3-9dcf-2767a869deaa"
      },
      "source": [
        "df_test_other = df[df['test_indication']=='Other']\n",
        "df_test_other\n",
        "print(len(df_test_other))\n",
        "print(len(df_test_other[df_test_other['corona_result'] == 'negative']))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "239404\n",
            "233862\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY-eu6IR18fJ"
      },
      "source": [
        "# Run this on the raw dataframe returned by pd.read_csv, include params for train/test split ratio (default: 80:20 split trainvalid/test & train/valid)\n",
        "def select_and_split_data(df, trainvalid_size=0.8):\n",
        "  df['test_date'] = pd.to_datetime(df['test_date'])\n",
        "  df = df[df['corona_result'].isin(['positive', 'negative'])]\n",
        "  \n",
        "  date_counts = df.groupby(['test_date']).count()['gender'] # take count of any column. They will all be same.\n",
        "  date_counts = date_counts.sort_index()\n",
        "  n_obs = df.shape[0]\n",
        "  cum_counts = date_counts.cumsum()\n",
        "  cdf = cum_counts / n_obs\n",
        "\n",
        "  max_training_date = cdf[cdf < trainvalid_size*trainvalid_size].index.max()\n",
        "  training_data = df[df['test_date'] <= max_training_date]\n",
        "\n",
        "  min_test_date = cdf[cdf > trainvalid_size].index.min()\n",
        "  test_data = df[df['test_date'] >= min_test_date]\n",
        "\n",
        "  valid_data = df[(max_training_date < df['test_date']) & (df['test_date'] < min_test_date)]\n",
        "\n",
        "  return training_data, valid_data, test_data"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftyqm2Wo2OiP"
      },
      "source": [
        "# train, valid, test = select_and_split_data(df)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rrZhJUn2XWL"
      },
      "source": [
        "def normalise(x):\n",
        "  if type(x) == str:\n",
        "    if x in ['0', '1']:\n",
        "      return int(x)\n",
        "    elif x == 'None':\n",
        "      return None\n",
        "  return x\n",
        "\n",
        "\n",
        "# Normalise columns to conver strings to ints and 'None' to np.nan\n",
        "# for col in train.columns:\n",
        "#   train.loc[:, col] = train[col].apply(normalise)\n",
        "#   valid.loc[:, col] = valid[col].apply(normalise)\n",
        "#   test.loc[:, col] = test[col].apply(normalise)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cyr-g2I22Zqq"
      },
      "source": [
        "# # Drop 'test_date' column and age column (TBC if we want to drop age)\n",
        "# train.drop(['test_date', 'age_60_and_above'], axis=1,inplace=True)\n",
        "# valid.drop(['test_date','age_60_and_above'], axis=1,inplace=True)\n",
        "# test.drop(['test_date','age_60_and_above'], axis=1,inplace=True)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggwNaEGm2hpo"
      },
      "source": [
        "# from sklearn.pipeline import Pipeline\n",
        "# from sklearn.compose import ColumnTransformer\n",
        "# from sklearn.impute import SimpleImputer\n",
        "\n",
        "# lb_train = LabelBinarizer()\n",
        "# lb_train.fit(train['corona_result'])\n",
        "\n",
        "# # Train a pipeline to transform categorical variables with imputation of missing values\n",
        "# categorical_transformer = Pipeline(steps=[\n",
        "#     ('imputer', SimpleImputer(strategy='most_frequent', missing_values=np.nan)),\n",
        "#     ('encoder', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "# preprocessor = ColumnTransformer(\n",
        "#     transformers=[\n",
        "#         ('cat', categorical_transformer, [0])\n",
        "#     ])\n",
        "\n",
        "# preprocessor.fit(train.drop('corona_result',axis=1))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQRohLR0R8wd"
      },
      "source": [
        "\n",
        "**GOOD PRACTICE**: To make your plots accessible to everyone, it is always a good idea to use colorblind-friendly palette for your plots. Check out [this](https://medium.com/cafe-pixo/inclusive-color-palettes-for-the-web-bbfe8cf2410e) for such a palette."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLRMrojV__Se"
      },
      "source": [
        "# Feature Engineering\n",
        "\n",
        "In this section, we will transform the features that models can operate upon. Note that this transformation doesn't have to be unique. \n",
        "It is very much dependent on the type of model you are building. \n",
        "\n",
        "Here is the list of questions to guide your feature engineering task \n",
        "\n",
        "1.   How will you represent the features in numerical format that can be accessible by model? \n",
        "2.   Are there any redundancies in your feature representation?\n",
        "3.   How will you represent targets in a format accessible to the model?\n",
        "\n",
        "Check out [`sklearn`'s preprocessing library](https://scikit-learn.org/stable/modules/preprocessing.html) for easy-to-use functions to do this. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGLQMUmWWKch"
      },
      "source": [
        "def preprocess(data, encoder, lb):\n",
        "  \"\"\"\n",
        "  Transforms `data` into format required for model building\n",
        "\n",
        "  Args:\n",
        "    data (pd.DataFrame): dataframe with columns `INPUT_FEAUTURES` and `TARGET_COLUMN`\n",
        "    encoder (sklearn.preprocessing.OneHotEncoder): A fitted OneHotEncoder to be used to transform `INPUT_FEATURES`\n",
        "    lb (sklearn.preprocessing.LabelBinarizer): A fitted LabelBinarizer to be used to transform `TARGET_COLUMN`\n",
        "  \n",
        "  Returns:\n",
        "    model_input (np.array): each row is an observation, columns are one-hot encoded features of `INPUT_FEATURES`\n",
        "    model_target (np.array): 1D array with 1 where `TARGET_COLUMN` is \"positive\" and 0 otherwise.\n",
        "  \"\"\"\n",
        "\n",
        "  ###### YOUR CODE ########\n",
        "  model_input = encoder.transform(data[INPUT_FEATURES]).todense()\n",
        "  model_target = lb.transform(data[TARGET_COLUMN]).flatten()\n",
        "  # model_target = lb.transform(data['corona_result']).flatten()\n",
        "  # model_input = encoder.transform(data.drop('corona_result', axis=1))\n",
        "\n",
        "  return model_input, model_target\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "lb.fit(training_data['corona_result'])\n",
        "\n",
        "encoder = OneHotEncoder()\n",
        "encoder.fit(training_data[INPUT_FEATURES])\n",
        "\n",
        "\n",
        "def preprocess_hack(data):\n",
        "  df_features = data.drop(\"test_date\",axis=1).copy()\n",
        "\n",
        "  symptoms = [\"cough\",\"fever\",\"sore_throat\",\"shortness_of_breath\",\"head_ache\"]\n",
        "  categorical = [\"age_60_and_above\",\"gender\",\"test_indication\",\"corona_result\"]\n",
        "\n",
        "  #preprocess symptoms - replace None with 0 and cast column as integer\n",
        "  for col in symptoms:\n",
        "      df_features[col].replace('None', 0, inplace=True)\n",
        "      df_features[col] = df_features[col].astype(np.uint8)\n",
        "\n",
        "  #preprocess categorical columns - OneHotEncode using get)dummies\n",
        "  for col in categorical:\n",
        "      tempdf = pd.get_dummies(df_features[col], prefix=col)\n",
        "      df_features = pd.merge(\n",
        "          left=df_features,\n",
        "          right=tempdf,\n",
        "          left_index=True,\n",
        "          right_index=True,\n",
        "      )\n",
        "      df_features = df_features.drop(columns=col)\n",
        "  df_features = df_features.drop(columns=[\"age_60_and_above_No\",\"age_60_and_above_None\",\n",
        "                                          \"gender_None\",\"gender_female\",\n",
        "                                          \"corona_result_negative\",\n",
        "                                          \"test_indication_Abroad\",\n",
        "                                          \"test_indication_Other\"])\n",
        "  \n",
        "  return df_features\n",
        "\n",
        "# X = preprocess_hack(df)\n",
        "# y = X[\"corona_result_positive\"]\n",
        "# X = X.drop(\"corona_result_positive\",axis=1)\n",
        "# print(X.shape)\n",
        "# print(y.shape)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpKCXmjGCxlQ"
      },
      "source": [
        "X_train, y_train = preprocess(training_data, encoder, lb)\n",
        "X_valid, y_valid = preprocess(valid_data, encoder, lb)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ2pT6gL2wsM"
      },
      "source": [
        "# X_train, y_train = preprocess(train, preprocessor, lb_train)\n",
        "# X_valid, y_valid = preprocess(valid, preprocessor, lb_train)\n",
        "# X_test, y_test = preprocess(test, preprocessor, lb_train)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N6PYvo8NUuE"
      },
      "source": [
        "# Model building\n",
        "\n",
        "In this section, we will build various classifiers using `sklearn`. You do not have to restrict yourself to `sklearn`. Please feel free to use any other library.\n",
        "\n",
        "**TRY:**  Try various classifiers that you have learned so far.\n",
        "Here is the list of models to try :\n",
        "\n",
        "*  Logistic Regssion: [User Guide](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression). [API](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
        "*   Decision Trees: [User Guide](https://scikit-learn.org/stable/modules/tree.html#classification). [API](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier). You can head down in the User Guide to [other Tree algorithms](https://scikit-learn.org/stable/modules/tree.html#tree-algorithms-id3-c4-5-c5-0-and-cart) if you fancy. \n",
        "*   Categorical Naive Bayes.[User Guide](https://scikit-learn.org/stable/modules/naive_bayes.html#categorical-naive-bayes). [API](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.CategoricalNB.html#sklearn.naive_bayes.CategoricalNB)\n",
        "*   Linear Discriminant Analysis. [User Guide](https://scikit-learn.org/stable/modules/lda_qda.html#). [API](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html#sklearn.discriminant_analysis.LinearDiscriminantAnalysis)\n",
        "*   Quadratic Discriminant Analysis. [User Guide](https://scikit-learn.org/stable/modules/lda_qda.html#). [API](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis)\n",
        "*   Support Vector Machines. [User Guide](https://scikit-learn.org/stable/modules/svm.html#classification). [API](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)\n",
        "*   Nearest neighbors classification. [User Guide](https://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-classification). [API](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)\n",
        "*   Neural networks - Multi-layer Perceptron (MLP). [User Guide](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#multi-layer-perceptron). [API](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPl0VoN--4Vw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7553de7-5b28-493d-a4d0-006fa5499e58"
      },
      "source": [
        "from sklearn import svm\n",
        "\n",
        "model = svm.LinearSVC()\n",
        "model.fit(X_train, y_train)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "          verbose=0)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7jUoSvY6lOK"
      },
      "source": [
        "import pickle\n",
        "\n",
        "# # Not feasible\n",
        "# # Save model in a file\n",
        "# with open('model_nusvc', 'wb') as file:\n",
        "#     pickle.dump(model, file)\n",
        "\n",
        "# # Assign model from a file to a new variable\n",
        "# with open('model_nusvc', 'rb') as file:\n",
        "#     model_nusvc = pickle.load(file)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I0Br2WSEKUh"
      },
      "source": [
        "\n",
        "0.7904915160490703\n",
        "# # Save model in a file\n",
        "# with open('model_linear', 'wb') as file:\n",
        "#     pickle.dump(model, file)\n",
        "\n",
        "# Assign model from a file to a new variable\n",
        "with open('model_linear', 'rb') as file:\n",
        "    model_linear_svc = pickle.load(file)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUFEDj14DOL0"
      },
      "source": [
        "# 0.5\n",
        "# # Save model in a file\n",
        "# with open('model_svc_impute_60', 'wb') as file:\n",
        "#     pickle.dump(model, file)\n",
        "\n",
        "# Assign model from a file to a new variable\n",
        "with open('model_svc_impute_60', 'rb') as file:\n",
        "    model_svc_impute_60 = pickle.load(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8mlxjGd4bYc"
      },
      "source": [
        "# 0.7843994109322655\n",
        "# # Save model in a file\n",
        "# with open('model_svc', 'wb') as file:\n",
        "#     pickle.dump(model, file)\n",
        "\n",
        "# Assign model from a file to a new variable\n",
        "with open('model_svc', 'rb') as file:\n",
        "    model_svc = pickle.load(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rGqBSQyYYTFn",
        "outputId": "ea5c9de7-9600-4e0f-d9ba-a12f3a4b0b56"
      },
      "source": [
        "# ?svm.SVC\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "C = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "gamma = ['scale', 'auto']\n",
        "random_grid = {'C': C,\n",
        "               'gamma': gamma,}\n",
        "\n",
        "svc_random = RandomizedSearchCV(estimator = model_linear_svc, param_distributions = random_grid, n_iter = 5, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "svc_random.fit(X_train, y_train)\n",
        "svc_random.best_params_"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 263, in __call__\n    for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\", line 263, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 504, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 236, in set_params\n    (key, self))\nValueError: Invalid parameter gamma for estimator LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n          verbose=0). Check the list of available parameters with `estimator.get_params().keys()`.\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-5cf13c63914b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msvc_random\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_linear_svc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distributions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0msvc_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0msvc_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid parameter gamma for estimator LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n          verbose=0). Check the list of available parameters with `estimator.get_params().keys()`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxyJDyo-AJoG"
      },
      "source": [
        "# best_model = svm.SVC(degree = 27, gamma = 'auto', kernel = 'poly', shrinking = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIobDchefBC8"
      },
      "source": [
        "# best_model = svm.SVC(degree = 27, gamma = 'scale', kernel = 'rbf', shrinking = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pES1nClSfvT7"
      },
      "source": [
        "# best_model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAdvBVDGf5na"
      },
      "source": [
        "# 0.7843994109322655\n",
        "# # Save model in a file\n",
        "# with open('best_model_svc', 'wb') as file:\n",
        "#     pickle.dump(best_model, file)\n",
        "\n",
        "# Assign model from a file to a new variable\n",
        "with open('best_model_svc', 'rb') as file:\n",
        "    best_model_svc = pickle.load(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjKae_XuAWLB"
      },
      "source": [
        "# 0.7843994109322655\n",
        "# Save model in a file\n",
        "with open('best_model_svc_impute_60', 'wb') as file:\n",
        "    pickle.dump(best_model, file)\n",
        "\n",
        "# Assign model from a file to a new variable\n",
        "with open('best_model_svc_impute_60', 'rb') as file:\n",
        "    best_model_svc_impute_60 = pickle.load(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZSS0TyANfG1"
      },
      "source": [
        "# Evaluate Model\n",
        "\n",
        "In this section, we will evaluate our model's performance on the validation dataset. \n",
        "\n",
        "Here are the list of questions to think about while deciding how to evaluate your model - \n",
        "*   Is accuracy the right metric to evaluate the model? Are inaccuracies correctly penalized in the accuracy metric?\n",
        "*  Would you think that the cost of false negative is more than the false positive? Is it dependent on the application?\n",
        "*  Which metric will minimize false negatives and false positives?\n",
        "*   Which dataset should you chose to evaluate the model? Validation or Test?\n",
        "What other metric is relevant in our context?  \n",
        "\n",
        "For benchmarking everyone’s results we will stick to ROC AUC score as a metric. \n",
        "There are standard functions to compute these scores in `sklearn`, so we will use them. \n",
        "Specifically, we will be using [`roc_auc_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score) and [`plot_roc_curve`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_roc_curve.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TGfy0kYV7pM"
      },
      "source": [
        "def evaluate(model, X, Y):\n",
        "  \"\"\"\n",
        "  Returns the AUC-ROC for `model` as evaluated on (X, Y)\n",
        "\n",
        "  Args:\n",
        "    model (): Any model that has a function predict_proba and returns probability for each row in `X`.\n",
        "    X (np.array): Input to the model containing feature values\n",
        "    Y (np.array): 1D array containing true class i.e. 0 or 1\n",
        "  \n",
        "  Returns:\n",
        "    (float): AUC ROC for the model\n",
        "  \"\"\"\n",
        "\n",
        "  # For example - \n",
        "  # y_score = model.predict_proba(X) # (n_samples, n_clases) with each value being the probability of being in that class\n",
        "  # return roc_auc_score(y_true=Y, y_score=y_score[:, 1])\n",
        "  Y_preds = model.predict(X)\n",
        "  print(model.get_params())\n",
        "  return roc_auc_score(Y, Y_preds)\n",
        "\n",
        "# X_valid, y_valid = preprocess(valid_data, encoder, lb)\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMIYd-DUDrVZ",
        "outputId": "5ef15ccf-8b24-476b-f7db-444bbd0ebe0c"
      },
      "source": [
        "evaluate(model_linear_svc, X_valid, y_valid)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 1.0, 'class_weight': None, 'dual': True, 'fit_intercept': True, 'intercept_scaling': 1, 'loss': 'squared_hinge', 'max_iter': 1000, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': None, 'tol': 0.0001, 'verbose': 0}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7904915160490703"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwgjIVL6BOk4"
      },
      "source": [
        "evaluate(best_model_svc_impute_60, X_valid, y_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFDKRi3z5OB3"
      },
      "source": [
        "evaluate(model_svc_impute_60, X_valid, y_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2mVQCikgrEA"
      },
      "source": [
        "evaluate(model_svc, X_valid, y_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir1vUUAPgtQW"
      },
      "source": [
        "evaluate(best_model_svc, X_valid, y_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "ILB2DzdmGhXd",
        "outputId": "efa8d25a-351e-4e5e-ccf0-f5c6f31d57d7"
      },
      "source": [
        "df = pd.DataFrame({'lab':['SVG on shuffle data', 'LinearSVG on shuffle data', 'SVC with age', 'LinearSVC with age'], 'val':[0.7945157102530405, 0.7824636235228732, 0.7843994109322655, 0.7904915160490703]})\n",
        "ax = df.plot.bar(x='lab', y='val', rot=0)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6n0jr-EekESj"
      },
      "source": [
        "# Hyperparameter Search\n",
        "\n",
        "In this section we will be searching for the best parameters to build our models. \n",
        "This is where we will use our validation dataset. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqSd5Bo3chPT"
      },
      "source": [
        "Hyperparameter search can become messy if you have lots of paramters. \n",
        "A brute force method to do such a search will be to do a grid search to fit tons of models. \n",
        "Thus, a smarter way to do hyperparameter search has been the subject of research. \n",
        "\n",
        "**TRY:** If interested, read [here](https://scikit-learn.org/stable/modules/grid_search.html) for more details and incorporate some of those ideas in the model building process. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkB6mMuSkkmN"
      },
      "source": [
        "# Report your results\n",
        "\n",
        "**NOTE:** You should use the test dataset only when you are done with hyperparameter search on your model. \n",
        "This is because the test dataset is not involved in the model building process, thereby making sure that the performance evaluation on the test dataset measures how well the proposed model is able to generalize."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxqeBPIMko9Z"
      },
      "source": [
        "X_test, Y_test = preprocess(test_data, encoder, lb)\n",
        "auc_score = evaluate(best_model, X_test, Y_test)\n",
        "print(f\"AUC-ROC on the test dataset:{auc_score}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmnEnKthyBGz"
      },
      "source": [
        "Is this the end?\n",
        "\n",
        "What do you need to do to make the model practically applicable? How would you use this model in the real life?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5sO-B1-BnFz"
      },
      "source": [
        "# Collaborate with Ensemble \n",
        "\n",
        "You can combine various models to form an ensemble model. \n",
        "There are various ways to combine these models. \n",
        "All of them serve a particular purpose (e.g. reducing variance, increasing accuracy. etc.). \n",
        "\n",
        "The simplest example of an ensemble is to combine the constituent models via voting. This can be done in two ways:\n",
        "*  soft voting - likelihood of the input belonging to a class is the mean of the likelihood predicted by the constituent models, \n",
        "*  hard-voting - likelihood of the input belonging to a class is determined by frequency of the constutuent models predicting that class for the input.\n",
        "\n",
        "Thus, if you are working in a team, let each member try out different models. At the end, combine your models and make an ensemble model. \n",
        "\n",
        "Here is the [User Guide](https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier) and [API](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier) for making such an ensemble model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awguX_CZs17n"
      },
      "source": [
        "# Extras: Class imbalance\n",
        "\n",
        "**TRY:** \n",
        " Why not try resampling techniques to optimize for ROC AUC?\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRQOtp3sNoKq"
      },
      "source": [
        "# Extras: Dimensionality Reduction\n",
        "\n",
        "**TRY:** You can try dimensionality reduction from 16 dimensions to just 2 dimensions and visualize 2D plot with just two categories - \"positive\" and \"negative\". \n",
        "To do this, try various dimension reduction techniques, for example, [LDA](https://scikit-learn.org/stable/modules/lda_qda.html#mathematical-formulation-of-lda-dimensionality-reduction), [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA), [t-SNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-B7PKHpewgz"
      },
      "source": [
        "# Poster template \n",
        "\n",
        "It is often the most difficult task to communicate the project's finding concisely in 1 minute or in a 1 slide. \n",
        "Therefore, our suggestion will be to touch upon the following points in your poster -  \n",
        "\n",
        "1. Briefly define the problem\n",
        "2. Briefly describe the dataset \n",
        "3. What did you learn about various models/techniques/etc.? e.g. \n",
        "4. What's the auc score of your final model did you get?\n",
        "\n",
        "If you want to learn what matters in building such posters, check out this great [YouTube video](https://www.youtube.com/watch?v=1RwJbhkCA58).\n",
        "Specifically, we should try and avoid posters with a lot of stuff to avoid cognitive overload. \n",
        "The templates suggested in the video can be found [here](https://osf.io/ef53g/). \n",
        "Note these are for academic papers, however, you can follow a similar ideology to concizsely display your work. "
      ]
    }
  ]
}